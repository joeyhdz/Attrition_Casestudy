CMP <- confusionMatrix(t)
knn_cm_plot <- as.data.frame(CMP$table)
knn_cm_plot$Prediction <- factor(knn_cm_plot$Prediction,
levels = rev(levels(knn_cm_plot$Reference)))
ggplot(knn_cm_plot, aes(Prediction, Reference, fill=(Freq))) +
geom_tile(show.legend = FALSE, color = 'black') +
geom_text(aes(label=(Freq))) +
scale_fill_gradient(low = "light blue", high = "steelblue") +
labs(x = "Reference", y = "Prediction") +
ggtitle("KNN Attrition Confusion Matrix") +
scale_color_fivethirtyeight() +
theme_hc()+ theme(plot.title = element_text(hjust = .5))
plot(roc(test$Attrition, attributes(knnClassification)$prob),
print.thres = T, print.auc=T, main = "AUC Curve for KNN Performance")
# ORIGINAL MODEL
set.seed(7)
splitPerc = .7
trainIndices = sample(1:dim(data)[1],round(splitPerc * dim(data)[1]))
train = data[trainIndices,]
test = data[-trainIndices,]
salFit <- lm(MonthlyIncome ~
JobLevel +
TotalWorkingYears +
JobRole, data=train)
summary(salFit)
salPrd <- predict(salFit, interval="predict",newdata = test)
RMSE <- sqrt(mean((salPrd[,1] - test$MonthlyIncome)^2))
RMSE # 1289 RMSE
# allows us to see vars in model and their stats.
stargazer(salFit, type = 'text') # adj r2 .92
# prints out vif
car::vif(salFit)
olsrr::ols_plot_diagnostics(salFit)
# data %>% select('MonthlyIncome','JobLevel','TotalWorkingYears','JobRole') %>%
#   ggpairs(title = "Correlation for Monthly Income using Linear Regression Features", aes(color= "blue"), color = "blue")
#
# # OLD KNN CODE
# iterations = 50
# set.seed(7)
# numks = round(sqrt(dim(scaled_data)[1])*1.2)
# masterAcc = matrix(nrow = iterations, ncol = numks)
# masterSpec= matrix(nrow = iterations, ncol = numks)
# masterSen = matrix(nrow = iterations, ncol = numks)
#
# for(j in 1:iterations) {
#   trainIndices = sample(1:dim(scaled_data)[1],round(splitPerc * dim(scaled_data)[1]))
#   train = scaled_data[trainIndices,]
#   test = scaled_data[-trainIndices,]
#   for(i in 1:numks) {
#     classifications = knn(train[,knnVar],test[,knnVar],as.factor(train$Attrition), prob = TRUE, k = i)
#     CM= confusionMatrix(table(as.factor(test$Attrition),classifications,
#                               dnn =c("Prediction", "Reference")), positive = '1')
#     masterAcc[j,i] = CM$overall[1]
#     masterSen[j,i] = CM$byClass[1]
#     masterSpec[j,i] = ifelse(is.na(CM$byClass[2]),0,CM$byClass[2])
#   }
# }
#
# # standard explore: avg - 86 / 76.8 / 86.6 / 78
# #knnVar <- c("OverTime", "Single", "JobSalesRepresentative",
#  #             "LessThan4k", "FreshWorker",
#   #            "LowLevel", "FreshHire", "LowInvolve", "NewRole", "NoBalance",
#    #           "AgeUnder35", "NoStock","JobSatisfaction","WorkLifeBalance",
#     #          "JobInvolvement","DueForPromotion","DistanceFromHome",
#      #         "MonthlyIncome")
#
# # top 10 : avg - 85.9 / 78 / 86 / 79
# knnVar <- c("OverTime","NoStock","LowLevel","JobSalesRepresentative",
#               "LowInvolve","LessThan4k","FreshHire","Single","NewRole",
#               "AgeUnder35")
#
# # the following is for forward model selection 85/67/86
# #knnVar <- c("OverTime", "NoStock","LowLevel", "LowInvolve","Sales", "JobSatisfaction",
#          #     "NoBalance", "LongCommute","JobInvolvement","NumCompaniesWorked","AgeUnder35",
#           #    "BusinessTravel","RelationshipSatisfaction","YearsSinceLastPromotion","EnvironmentSatisfaction",
#            #  "FreshHire","JobHealthcareRepresentative")
#
# for(j in 1:iterations) {
#   trainIndices = sample(1:dim(scaled_data)[1],round(splitPerc * dim(scaled_data)[1]))
#   train = scaled_data[trainIndices,]
#   test = scaled_data[-trainIndices,]
#   for(i in 1:numks) {
#     classifications = knn(train[,knnVar],test[,knnVar],as.factor(train$Attrition), prob = TRUE, k = i)
#     CM= confusionMatrix(table(as.factor(test$Attrition),classifications,
#                               dnn =c("Prediction", "Reference")), positive = '1')
#     masterAcc[j,i] = CM$overall[1]
#     masterSen[j,i] = CM$byClass[1]
#     masterSpec[j,i] = ifelse(is.na(CM$byClass[2]),0,CM$byClass[2])
#   }
# }
#
# MeanAcc <- colMeans(masterAcc)
# MeanSen <- colMeans(masterSen)
# MeanSpec <- colMeans(masterSpec)
# plot(seq(1,numks), MeanAcc, main="K value determination", xlab="Value of K")
#
# which.max(MeanAcc) # suggested k for best accuracy
# which.max(MeanSen)
# which.max(MeanSpec)
#
# k <- which.max(MeanAcc)
# specs <- c(MeanAcc[k], MeanSen[k], MeanSpec[k])
# names(specs) <- c("Avg Acc", "Avg Sen", "Avg Spec")
# specs
# #
# # classifications = knn(train[,knnVar],test[,knnVar],as.factor(train$Attrition), prob = TRUE, k = k)
# # #confusionMatrix(table(test$Attrition,classifications, dnn = c("Prediction", "Reference")), positive = '1')
# #
# # #attributes(classifications)$prob
# #
# #
# # #roc(test$Attrition, attributes(classifications)$prob)
# #
# # plot(roc(test$Attrition, attributes(classifications)$prob),
# #      print.thres = T,
# #      print.auc=T)
# #
# u <-union(classifications,test[,knnVar])
# t <- table(factor(classifications,u), factor(test$Attrition,u), dnn = c("Prediction", "Reference"))
# CMP <- confusionMatrix(t)
#
# cat("Accuracy:", CM$overall[1]*100, "%",
#     "\nSensitivity:",CM$byClass[1]*100, "%",
#     "\nSpecificity:",CM$byClass[2]*100, "%")
#
# knn_plot <- as.data.frame(CM$table)
#
# knn_plot$Prediction <- factor(knn_plot$Prediction, levels = rev(levels(knn_plot$Reference)))
#
# ggplot(knn_plot, aes(Prediction, Reference, fill=(Freq))) +
#   geom_tile(show.legend = FALSE) + geom_text(aes(label=(Freq))) +
#   scale_fill_gradient(low = "white", high = "steelblue") +
#   labs(x = "Reference", y = "Prediction")
# # SECOND PLACE MODEL LR MONTHLY INCOME
# set.seed(7)
# trainIndices = sample(1:dim(data)[1],round(splitPerc * dim(data)[1]))
# train = data[trainIndices,]
# test = data[-trainIndices,]
#
# salFit2 <- lm(MonthlyIncome ~ NewRole + JobRole+ TotalWorkingYears +
#                 Sales + LowInvolve + GenZ,
#               data=train)
# # rm jobRole due to high VIF ? other reasons? # rm LowLevl
# summary(salFit2)
#
# # prediction with new fit
# salPrd2 <- predict(salFit2, interval="predict",newdata = test)
#
# # RMSE for new fit
# RMSE <- sqrt(mean((salPrd2[,1] - test$MonthlyIncome)^2))
# RMSE # 625
#
# # allows us to see vars in model and their stats.
# stargazer(salFit2, type = 'text') # .975 adj r2
# # prints out vif
# car::vif(salFit2) # no outlier VIF values
# iterations = 100
# masterAcc_nb = matrix(nrow = iterations)
# masterSpec_nb = matrix(nrow = iterations)
# masterSen_nb = matrix(nrow = iterations)
# splitPerc <- .7
#
# nbArray <- c("OverTime","NewRole", "WorkLifeBalance", "JobInvolvement",
#              "JobSatisfaction", "Gender", "EnvironmentSatisfaction",
#              "BusinessTravel", "MonthlyIncome", "FreshHire", "AgeUnder35",
#              "LogIncome", "Divorced", "HourlyOver40", "NoStock","HighPerform")
#
# set.seed(7)
# for(j in 1:iterations){
#   trainIndices = sample(1:dim(data)[1],round(splitPerc * dim(data)[1]))
#   train = data[trainIndices,]
#   test = data[-trainIndices,]
#   model = naiveBayes(train[,nbArray],as.factor(train$Attrition))
#   CM_NB = confusionMatrix(table(predict(model,test[,nbArray]),as.factor(test$Attrition), dnn = c("Prediction", "Reference")), positive = '1')
#   masterAcc_nb[j] = CM_NB$overall[1]
#   masterSen_nb[j] = CM_NB$byClass[1]
#   masterSpec_nb[j] = CM_NB$byClass[2]
# }
#
# # function for plotting confusion matrix
# ggplotConfusionMatrix_nb <- function(m){
#   p <- ggplot(data= as.data.frame(m$table),
#               aes(x = Reference, y = Prediction)) +
#     geom_tile(aes(fill = log(Freq)), color = "white") +
#     scale_fill_gradient(low = "white", high = "steelblue") +
#     geom_text(aes(x = Reference, y = Prediction, label = Freq)) +
#     theme(legend.position = 'none') +
#     ggtitle("Confusion Matrix for Naive Bayes Model")
#   return(p)
# }
#
#
# ggplotConfusionMatrix_nb(CM_NB)
#
# #confusionMatrix(table(predict(model,test[,nbArray]), as.factor(test$Attrition),
#  #                     dnn = c("Prediction", "Reference")), positive = '1')
#
# #specs_nb <- c(colMeans(masterAcc),colMeans(masterSen),colMeans(masterSpec))
#
# #names(specs_nb) <- c("Avg Accuracy", "Avg Sensitivity", "Avg Specificity")
# #specs_nb
# code for using selection model, and trying regression for var selection.
#set.seed(7)
#splitPerc = .7
#trainIndices = sample(1:dim(rdata)[1],round(splitPerc * dim(rdata)[1]))
#train = rdata[trainIndices,]
#test = rdata[-trainIndices,]
#lreg <- glm(formula = Attrition ~ .,
#             data= rdata, family="binomial")
#used the following for the knn model
#lreg <- lm(formula = Attrition ~ .,
#data= rdata)
# using the selected models from forward selection:
#lreg <- lm(formula = Attrition ~OverTime+NoStock+LowLevel+LowInvolve+Sales+JobSatisfaction+
#             NoBalance+LongCommute+JobInvolvement+NumCompaniesWorked+AgeUnder35+
#            BusinessTravel+RelationshipSatisfaction+YearsSinceLastPromotion+EnvironmentSatisfaction+
#           FreshHire+JobHealthcareRepresentative, data = rdata)
#atPrd <- predict(lreg, type="response", newdata = test)
#actualPred <- ifelse(atPrd > 0.5, 1, 0)
#confusionMatrix(table(as.factor(actualPred), as.factor(test$Attrition),
#                     dnn = c("Prediction", "Reference")), positive = '1')
#plot(roc(response = lreg$y, predictor = lreg$
#         fitted.values, plot = T), print.thres = "best", print.auc = T)
#ols_step_forward_p(lreg, penter = .05, details = TRUE)
# LOOP FOR AVG RMSE
# get average RMSE for model with adjusted fit
trainIndices = sample(1:dim(data)[1],round(splitPerc * dim(data)[1]))
train = data[trainIndices,]
test = data[-trainIndices,]
iterations = 100
numks = round(sqrt(dim(data)[1])*1.2)
masterRMSE = matrix(nrow = iterations, ncol = numks)
set.seed(7)
for(j in 1:iterations){
trainIndices = sample(1:dim(data)[1],round(splitPerc * dim(data)[1]))
train = data[trainIndices,]
test = data[-trainIndices,]
for(i in 1:numks){
# Fit
salFit2 <- lm(MonthlyIncome ~ LogIncome + LowLevel + NewRole + TotalWorkingYears +
Sales + LowInvolve + GenZ + JobLevel, data=train)
# prediction
salPrd <- predict(salFit2, interval="predict", newdata = test)
# RMSE for Prediction
RMSE <- sqrt(mean((salPrd[,1] - test$MonthlyIncome)^2))
# Assign RMSE into master RMSE so we can get avgs
masterRMSE[j,i] = RMSE
}
}
avgrmse <- colMeans(masterRMSE)
# this was a fit of all so that i could run the stepwise and see what feats to keep etc.
#
# ols_step_both_p(testFit, prem = .05, details = TRUE)
#
#testFit <- lm(MonthlyIncome ~ JobLevel + TotalWorkingYears +
#               JobManager + BusinessTravel + DailyRate+
#              Department + DistanceFromHome + Education+ EducationField +
#             EmployeeCount + EnvironmentSatisfaction + Gender + HourlyRate +
#            JobInvolvement + LogIncome + MonthlyOver15k + LowTraining +
#           NoStock + HighPerform + DueForPromotion + AgeUnder35 + LongCommute +
#          HighSatisfaction + SalaryHike + NoBalance + NewRole + LowInvolve +
#         WorkMore30 + FreshHire + LowLevel + LessThan4k + Boomersii +
#        GenZ + GenX + Millennials + Phd + NoCollege + SomeCollege + Masters +
#       Bachelors + JobLaboratoryTechnician + JobHumanResources + JobHealthcareRepresentative +
#      JobManager + JobSalesRepresentative + JobSalesExecutive + JobResearchScientist +
#     JobResearchDirector + JobManufacturingDirector + EduOther + EduTechnicalDegree +
#    EduMarketing + EduMedical + EduLifeSciences + Divorced + Married + Single + Sales +
#   ResearchDevelopment + HumanResources + Generations + EducationLevel + YearsWithCurrManager +
#  YearsSinceLastPromotion + YearsInCurrentRole + YearsAtCompany + JobInvolvement +
# JobLevel + JobRole + JobSatisfaction + MaritalStatus + MonthlyRate + NumCompaniesWorked +
#OverTime + StockOptionLevel , data = train)
# Up / Down Samples
# While i would have loved for this to work for enhancing the model... I don't think
# i'm conceputally at a level to where these things would help me... was a good try though!
# # LOOCV
#
# knn.cv(train[,knnVar],as.factor(train$Attrition), k = 3)
# set.seed(7)
# classification = knn.cv(train[,knnVar],as.factor(train$Attrition), k = 3)
# classification
#
# data.frame(classification = classification, true = as.factor(train$Attrition))
# confusionMatrix(classification, as.factor(train$Attrition))
# glimpse(scaled_data)
#
#
# # Down Sample: Simple random sampling is used to down-sample for the majority classes.
# # minority class data is left intact and the samples are re-ordered in the down-sample version
# down_sample<- downSample(x = scaled_data, y = as.factor(scaled_data$Attrition), list = FALSE, yname = "class")
# table(down_sample$Attrition)
#
# # Up Sample
# up_sample <- upSample(x = scaled_data, y = as.factor(scaled_data$Attrition), list = FALSE, yname = "class")
# table(up_sample$Attrition)
#
# # UP SAMPLE KNN - as good as a random guess
#
# iterations = 50
# set.seed(7)
# numks = round(sqrt(dim(up_sample)[1])*1.2)
# masterAcc = matrix(nrow = iterations, ncol = numks)
# masterSpec= matrix(nrow = iterations, ncol = numks)
# masterSen = matrix(nrow = iterations, ncol = numks)
#
# for(j in 1:iterations) {
#   trainIndices = sample(1:dim(up_sample)[1],round(splitPerc * dim(up_sample)[1]))
#   train = up_sample[trainIndices,]
#   test = up_sample[-trainIndices,]
#   for(i in 1:numks) {
#     # predict using i-th value of k
#     classifications = knn(train[,knnVar],test[,knnVar],as.factor(train$Attrition), prob = TRUE, k = i)
#     CM= confusionMatrix(table(as.factor(test$Attrition),classifications, dnn = c("Prediction", "Reference")), positive = '1')
#     masterAcc[j,i] = CM$overall[1]
#     masterSen[j,i] = CM$byClass[1]
#     masterSpec[j,i] = ifelse(is.na(CM$byClass[2]),0,CM$byClass[2])
#   }
# }
#
#
# MeanAcc <- colMeans(masterAcc)
# MeanSen <- colMeans(masterSen)
# MeanSpec <- colMeans(masterSpec)
# plot(seq(1,numks), MeanAcc, main="K value determination", xlab="Value of K")
#
# k <- which.max(MeanAcc)
# specs <- c(MeanAcc[k], MeanSen[k], MeanSpec[k])
# names(specs) <- c("Avg Acc", "Avg Sen", "Avg Spec")
# specs
#
# classifications = knn(train[,knnVar],test[,knnVar],as.factor(train$Attrition), prob = TRUE, k = k)
#
# confusionMatrix(table(test$Attrition,classifications, dnn = c("Prediction", "Reference")), positive = '1')
#
#
# plot(roc(test$Attrition, attributes(classifications)$prob),
#      print.thres = T,
#      print.auc=T)
#
#
#
# # DOWN SAMPLE KNN - worse than a guess
#
# iterations = 50
# set.seed(7)
# numks = round(sqrt(dim(down_sample)[1])*1.2)
# masterAcc = matrix(nrow = iterations, ncol = numks)
# masterSpec= matrix(nrow = iterations, ncol = numks)
# masterSen = matrix(nrow = iterations, ncol = numks)
#
# for(j in 1:iterations) {
#   trainIndices = sample(1:dim(down_sample)[1],round(splitPerc * dim(down_sample)[1]))
#   train = down_sample[trainIndices,]
#   test = down_sample[-trainIndices,]
#   for(i in 1:numks) {
#     # predict using i-th value of k
#     classifications = knn(train[,knnVar],test[,knnVar],as.factor(train$Attrition), prob = TRUE, k = i)
#     CM= confusionMatrix(table(as.factor(test$Attrition),classifications, dnn = c("Prediction", "Reference")), positive = '1')
#     masterAcc[j,i] = CM$overall[1]
#     masterSen[j,i] = CM$byClass[1]
#     masterSpec[j,i] = ifelse(is.na(CM$byClass[2]),0,CM$byClass[2])
#   }
# }
#
#
# MeanAcc <- colMeans(masterAcc)
# MeanSen <- colMeans(masterSen)
# MeanSpec <- colMeans(masterSpec)
# plot(seq(1,numks), MeanAcc, main="K value determination", xlab="Value of K")
#
# k <- which.max(MeanAcc)
# specs <- c(MeanAcc[k], MeanSen[k], MeanSpec[k])
# names(specs) <- c("Avg Acc", "Avg Sen", "Avg Spec")
# specs
#
# classifications = knn(train[,knnVar],test[,knnVar],as.factor(train$Attrition), prob = TRUE, k = k)
#
# confusionMatrix(table(test$Attrition,classifications, dnn = c("Prediction", "Reference")), positive = '1')
#
#
# plot(roc(test$Attrition, attributes(classifications)$prob),
#      print.thres = T,
#      print.auc=T)
# prints out vif
car::vif(salPrd)
# prints out vif
car::vif(salFit)
# ORIGINAL MODEL
set.seed(7)
splitPerc = .7
trainIndices = sample(1:dim(data)[1],round(splitPerc * dim(data)[1]))
train = data[trainIndices,]
test = data[-trainIndices,]
income_fit <- lm(MonthlyIncome ~
JobLevel +
TotalWorkingYears +
JobRole, data=train)
summary(income_fit)
income_pred <- predict(income_fit, interval="predict",newdata = test)
RMSE <- sqrt(mean((income_pred[,1] - test$MonthlyIncome)^2))
RMSE # 1289 RMSE
# allows us to see vars in model and their stats.
stargazer(income_fit, type = 'text') # adj r2 .92
# prints out vif
car::vif(salFit)
olsrr::ols_plot_diagnostics(salFit)
# ORIGINAL MODEL
set.seed(7)
splitPerc = .7
trainIndices = sample(1:dim(data)[1],round(splitPerc * dim(data)[1]))
train = data[trainIndices,]
test = data[-trainIndices,]
income_fit <- lm(MonthlyIncome ~
JobLevel +
TotalWorkingYears +
JobRole, data=train)
income_pred <- predict(income_fit, interval="predict",newdata = test)
RMSE <- sqrt(mean((income_pred[,1] - test$MonthlyIncome)^2))
RMSE # 1289 RMSE
# allows us to see vars in model and their stats.
stargazer(income_fit, type = 'text') # adj r2 .92
# prints out vif
car::vif(salFit)
olsrr::ols_plot_diagnostics(salFit)
# ORIGINAL MODEL
set.seed(7)
splitPerc = .7
trainIndices = sample(1:dim(data)[1],round(splitPerc * dim(data)[1]))
train = data[trainIndices,]
test = data[-trainIndices,]
income_fit <- lm(MonthlyIncome ~
JobLevel +
TotalWorkingYears +
JobRole, data=train)
income_pred <- predict(income_fit, interval="predict",newdata = test)
RMSE <- sqrt(mean((income_pred[,1] - test$MonthlyIncome)^2))
RMSE # 1289 RMSE
# allows us to see vars in model and their stats.
stargazer(income_fit, type = 'text') # adj r2 .92
# prints out vif
car::vif(salFit)
olsrr::ols_plot_diagnostics(income_fit)
ols_plot_diagnostics(income_fit)
?cat
cat("RMSE",RMSE)
cat("RMSE = ",RMSE)
acp <- AttritionCorrelation %>% top_n(10) %>% mutate(Feature = factor(Feature, Feature)) %>%
ggplot(aes(Feature, Attrition, fill = Feature)) + geom_col(show.legend = FALSE) +
coord_flip() + labs(title = "Top 10 Correlative Factors for Attrition") +
ylab("Correlation Between Features and Attrition") +
scale_fill_discrete(guide = guide_legend(reverse = TRUE))+
scale_color_fivethirtyeight() +
theme_hc()
icp <- IncomeCorrelation %>% top_n(10) %>% mutate(Feature = factor(Feature, Feature)) %>%
ggplot(aes(Feature, MonthlyIncome, fill = Feature)) +
geom_col(show.legend = FALSE) +
labs(title = "Top 10 Correlative Factors for Monthly Income") +
ylab("Correlation Between Features and Monthly Income") + coord_flip() +
scale_color_fivethirtyeight() +
theme_hc()
gridExtra::grid.arrange(acp, icp, ncol = 4)
acp <- AttritionCorrelation %>% top_n(10) %>% mutate(Feature = factor(Feature, Feature)) %>%
ggplot(aes(Feature, Attrition, fill = Feature)) + geom_col(show.legend = FALSE) +
coord_flip() + labs(title = "Top 10 Correlative Factors for Attrition") +
ylab("Correlation Between Features and Attrition") +
scale_fill_discrete(guide = guide_legend(reverse = TRUE))+
scale_color_fivethirtyeight() +
theme_hc()
icp <- IncomeCorrelation %>% top_n(10) %>% mutate(Feature = factor(Feature, Feature)) %>%
ggplot(aes(Feature, MonthlyIncome, fill = Feature)) +
geom_col(show.legend = FALSE) +
labs(title = "Top 10 Correlative Factors for Monthly Income") +
ylab("Correlation Between Features and Monthly Income") + coord_flip() +
scale_color_fivethirtyeight() +
theme_hc()
gridExtra::grid.arrange(acp, icp, ncol = 2)
gridExtra::grid.arrange(acp, icp, ncol = 1)
gridExtra::grid.arrange(acp, icp, ncol = 2)
acp <- AttritionCorrelation %>% top_n(10) %>% mutate(Feature = factor(Feature, Feature)) %>%
ggplot(aes(Feature, Attrition, fill = Feature)) + geom_col(show.legend = FALSE) +
labs(title = "Top 10 Correlative Factors for Attrition") +
ylab("Correlation Between Features and Attrition") +
scale_fill_discrete(guide = guide_legend(reverse = TRUE))+
scale_color_fivethirtyeight() +
theme_hc()
icp <- IncomeCorrelation %>% top_n(10) %>% mutate(Feature = factor(Feature, Feature)) %>%
ggplot(aes(Feature, MonthlyIncome, fill = Feature)) +
geom_col(show.legend = FALSE) +
labs(title = "Top 10 Correlative Factors for Monthly Income") +
ylab("Correlation Between Features and Monthly Income") +
scale_color_fivethirtyeight() +
theme_hc()
gridExtra::grid.arrange(acp, icp, ncol = 2)
acp <- AttritionCorrelation %>% top_n(10) %>% mutate(Feature = factor(Feature, Feature)) %>%
ggplot(aes(Feature, Attrition, fill = Feature)) + geom_col(show.legend = FALSE) +
coord_flip() + labs(title = "Top 10 Correlative Factors for Attrition") +
ylab("Correlation Between Features and Attrition") +
scale_fill_discrete(guide = guide_legend(reverse = TRUE))+
scale_color_fivethirtyeight() +
theme_hc()
icp <- IncomeCorrelation %>% top_n(10) %>% mutate(Feature = factor(Feature, Feature)) %>%
ggplot(aes(Feature, MonthlyIncome, fill = Feature)) +
geom_col(show.legend = FALSE) +
labs(title = "Top 10 Correlative Factors for Monthly Income") +
ylab("Correlation Between Features and Monthly Income") + coord_flip() +
scale_color_fivethirtyeight() +
theme_hc()
gridExtra::grid.arrange(acp, icp, ncol = 2)
gridExtra::grid.arrange(acp, icp, nrow = 2)
gridExtra::grid.arrange(acp, icp, nrow = 2, ncol = 2)
gridExtra::grid.arrange(acp, icp, nrow = 2)
acp
?grid.arrange
